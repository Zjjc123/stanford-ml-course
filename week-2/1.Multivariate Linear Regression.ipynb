{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "powerful-skill",
   "metadata": {},
   "source": [
    "# Multiple Features\n",
    "\n",
    "- Multiple variables $x_1, x_2, x_3, x_4...$\n",
    "    - for example: size, length, weight, height, etc.\n",
    "\n",
    "## Notations\n",
    "\n",
    "$n$ = number of features\n",
    "\n",
    "$i$ = index of the training data in the training set\n",
    "\n",
    "$x^{(i)}$= input (features) of $i^{th}$ training example\n",
    "\n",
    "$x^{(i)}_j$= value of feature $j$ in $i^{th}$ training example\n",
    "\n",
    "## Multivariate Linear Regression\n",
    "\n",
    "$h_\\theta(x) = \\theta_0 + \\theta_1x+\\theta_2x_2+\\theta_3x_3+\\theta_4x_4+...$\n",
    "\n",
    "for convenience of notation $x_0 = 1$\n",
    "\n",
    "$x = \\begin{bmatrix}\n",
    "x_0\\\\ \n",
    "x_1\\\\ \n",
    "x_2\\\\ \n",
    "x_3\\\\ \n",
    "...\\\\\n",
    "x_n\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$\\theta = \\begin{bmatrix}\n",
    "\\theta_0\\\\ \n",
    "\\theta_1\\\\ \n",
    "\\theta_2\\\\ \n",
    "\\theta_3\\\\ \n",
    "...\\\\\n",
    "\\theta_n\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$h_\\theta(x) = \\theta_0x_0 + \\theta_1x+\\theta_2x_2+\\theta_3x_3+\\theta_4x_4+...$\n",
    "\n",
    "$=\\theta^Tx$\n",
    "\n",
    "$\\theta$ Transpose time x = hypothesis\n",
    "\n",
    "$\\theta^T = \\begin{bmatrix}\n",
    "\\theta_0& \n",
    "\\theta_1& \n",
    "\\theta_2& \n",
    "\\theta_3&\n",
    "...&\n",
    "\\theta_n\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$x = \\begin{bmatrix}\n",
    "x_0\\\\ \n",
    "x_1\\\\ \n",
    "x_2\\\\ \n",
    "x_3\\\\ \n",
    "...\\\\\n",
    "x_n\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-membrane",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "\n",
    "Parameters: $\\theta_0, \\theta_1,....,\\theta_n$ is denoted as just $\\theta$\n",
    "\n",
    "$J(\\theta_0, \\theta_1, ...,\\theta_n)$  is denoted as just $J(\\theta)$\n",
    "\n",
    "**Cost Function**\n",
    "\n",
    "$J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2$\n",
    "\n",
    "Repeat {\n",
    "\n",
    "$\\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial\\theta_j}J(\\theta)$\n",
    "\n",
    "}\n",
    "\n",
    "Algorithm (n â‰¥ 1):\n",
    "\n",
    "Repeat {\n",
    "\n",
    "$\\theta_j := \\theta_j-\\alpha\\frac{1}{m}\\sum_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})x^{(i)}_j$\n",
    "\n",
    "}\n",
    "\n",
    "The end $x^{(i)}_j$ term is the power rule from the partial derivative when the cost function's partial derivative taken in respect to $\\theta_j$\n",
    "\n",
    "$\\frac{\\partial}{\\partial\\theta_j}h_\\theta(x) = \\theta_0x_0 + \\theta_1x+\\theta_2x_2+\\theta_3x_3+\\theta_4x_4+... = x_j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "seven-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "disciplinary-crest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>price</th>\n",
       "      <th>transmission</th>\n",
       "      <th>mileage</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>tax</th>\n",
       "      <th>mpg</th>\n",
       "      <th>engineSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1</td>\n",
       "      <td>2017</td>\n",
       "      <td>12500</td>\n",
       "      <td>Manual</td>\n",
       "      <td>15735</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>150</td>\n",
       "      <td>55.4</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A6</td>\n",
       "      <td>2016</td>\n",
       "      <td>16500</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>36203</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>20</td>\n",
       "      <td>64.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1</td>\n",
       "      <td>2016</td>\n",
       "      <td>11000</td>\n",
       "      <td>Manual</td>\n",
       "      <td>29946</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>30</td>\n",
       "      <td>55.4</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A4</td>\n",
       "      <td>2017</td>\n",
       "      <td>16800</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>25952</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>67.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3</td>\n",
       "      <td>2019</td>\n",
       "      <td>17300</td>\n",
       "      <td>Manual</td>\n",
       "      <td>1998</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>145</td>\n",
       "      <td>49.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  year  price transmission  mileage fuelType  tax   mpg  engineSize\n",
       "0    A1  2017  12500       Manual    15735   Petrol  150  55.4         1.4\n",
       "1    A6  2016  16500    Automatic    36203   Diesel   20  64.2         2.0\n",
       "2    A1  2016  11000       Manual    29946   Petrol   30  55.4         1.4\n",
       "3    A4  2017  16800    Automatic    25952   Diesel  145  67.3         2.0\n",
       "4    A3  2019  17300       Manual     1998   Petrol  145  49.6         1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get audi car price dataset\n",
    "# https://www.kaggle.com/adityadesai13/used-car-dataset-ford-and-mercedes\n",
    "dataset = pd.read_csv('data/audi.csv')\n",
    "\n",
    "# print dataset\n",
    "dataset.iloc[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "funny-leave",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>price</th>\n",
       "      <th>transmission</th>\n",
       "      <th>mileage</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>tax</th>\n",
       "      <th>mpg</th>\n",
       "      <th>engineSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A4</td>\n",
       "      <td>2017</td>\n",
       "      <td>16800</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>25952</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>67.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A4</td>\n",
       "      <td>2016</td>\n",
       "      <td>11750</td>\n",
       "      <td>Manual</td>\n",
       "      <td>75185</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>20</td>\n",
       "      <td>70.6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A4</td>\n",
       "      <td>2017</td>\n",
       "      <td>18500</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>17418</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>62.8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>A4</td>\n",
       "      <td>2018</td>\n",
       "      <td>17200</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>25138</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>70.6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>A4</td>\n",
       "      <td>2017</td>\n",
       "      <td>16000</td>\n",
       "      <td>Manual</td>\n",
       "      <td>29063</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>70.6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  year  price transmission  mileage fuelType  tax   mpg  engineSize\n",
       "3     A4  2017  16800    Automatic    25952   Diesel  145  67.3         2.0\n",
       "7     A4  2016  11750       Manual    75185   Diesel   20  70.6         2.0\n",
       "25    A4  2017  18500    Automatic    17418   Diesel  145  62.8         2.0\n",
       "28    A4  2018  17200    Automatic    25138   Diesel  145  70.6         2.0\n",
       "38    A4  2017  16000       Manual    29063   Diesel  145  70.6         2.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get only A4's\n",
    "dataset['model'] = dataset['model'].str.strip()\n",
    "a4_dataset = dataset[dataset['model'] == \"A4\"]\n",
    "a4_dataset.iloc[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "prime-shame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000e+00 2.5952e+04 2.0000e+00]\n",
      " [1.0000e+00 7.5185e+04 2.0000e+00]\n",
      " [1.0000e+00 1.7418e+04 2.0000e+00]\n",
      " ...\n",
      " [1.0000e+00 2.3700e+04 2.0000e+00]\n",
      " [1.0000e+00 7.8000e+04 3.0000e+00]\n",
      " [1.0000e+00 9.5000e+04 2.0000e+00]]\n",
      "[16800 11750 18500 ... 20995  9995  6995]\n"
     ]
    }
   ],
   "source": [
    "# features are: mileage, tax, mpg, and engine size\n",
    "# input data of x0, x1, x2, ...\n",
    "# x0 is set to 1 for matrix multiplicaiton\n",
    "\n",
    "input_data = np.array([np.ones(a4_dataset.shape[0]), a4_dataset.mileage, a4_dataset.engineSize])\n",
    "input_data = input_data.transpose(1, 0);\n",
    "output_data = np.array(a4_dataset.price)\n",
    "print(input_data)\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "completed-neighborhood",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.1753632  0.47619048]\n",
      " [1.         0.50804108 0.47619048]\n",
      " [1.         0.11769714 0.47619048]\n",
      " ...\n",
      " [1.         0.16014596 0.47619048]\n",
      " [1.         0.52706264 0.71428571]\n",
      " [1.         0.64193527 0.47619048]]\n",
      "cost before: [2.38624623e+08]\n",
      "iteration:  0 cost:  [2.01136342e+08]\n",
      "iteration:  1 cost:  [1.69972309e+08]\n",
      "iteration:  2 cost:  [1.44051461e+08]\n",
      "iteration:  3 cost:  [1.22478806e+08]\n",
      "iteration:  4 cost:  [1.04513278e+08]\n",
      "iteration:  5 cost:  [89541152.10816734]\n",
      "iteration:  6 cost:  [77054070.16496317]\n",
      "iteration:  7 cost:  [66630858.87655707]\n",
      "iteration:  8 cost:  [57922498.73074442]\n",
      "iteration:  9 cost:  [50639690.26148445]\n",
      "iteration:  10 cost:  [44542570.00184596]\n",
      "iteration:  11 cost:  [39432203.58296182]\n",
      "iteration:  12 cost:  [35143548.29352237]\n",
      "iteration:  13 cost:  [31539630.74027502]\n",
      "iteration:  14 cost:  [28506729.32867099]\n",
      "iteration:  15 cost:  [25950387.71829566]\n",
      "iteration:  16 cost:  [23792115.52577628]\n",
      "iteration:  17 cost:  [21966657.44423519]\n",
      "iteration:  18 cost:  [20419732.52872569]\n",
      "iteration:  19 cost:  [19106162.40998028]\n",
      "iteration:  20 cost:  [17988321.2629223]\n",
      "iteration:  21 cost:  [17034851.98310025]\n",
      "iteration:  22 cost:  [16219602.63617154]\n",
      "iteration:  23 cost:  [15520745.19212586]\n",
      "iteration:  24 cost:  [14920045.1258573]\n",
      "iteration:  25 cost:  [14402255.89763271]\n",
      "iteration:  26 cost:  [13954616.81823795]\n",
      "iteration:  27 cost:  [13566436.51716976]\n",
      "iteration:  28 cost:  [13228747.30296582]\n",
      "iteration:  29 cost:  [12934018.24403284]\n",
      "iteration:  30 cost:  [12675916.89823611]\n",
      "iteration:  31 cost:  [12449111.35617291]\n",
      "iteration:  32 cost:  [12249105.69939451]\n",
      "iteration:  33 cost:  [12072103.16287932]\n",
      "iteration:  34 cost:  [11914892.27379437]\n",
      "iteration:  35 cost:  [11774752.05155751]\n",
      "iteration:  36 cost:  [11649373.02681547]\n",
      "iteration:  37 cost:  [11536791.3934741]\n",
      "iteration:  38 cost:  [11435334.06844048]\n",
      "iteration:  39 cost:  [11343572.81486954]\n",
      "iteration:  40 cost:  [11260285.90017231]\n",
      "iteration:  41 cost:  [11184426.02119542]\n",
      "iteration:  42 cost:  [11115093.44520256]\n",
      "iteration:  43 cost:  [11051513.49434133]\n",
      "iteration:  44 cost:  [10993017.64957803]\n",
      "iteration:  45 cost:  [10939027.67293658]\n",
      "iteration:  46 cost:  [10889042.24867438]\n",
      "iteration:  47 cost:  [10842625.7283955]\n",
      "iteration:  48 cost:  [10799398.6350442]\n",
      "iteration:  49 cost:  [10759029.63872196]\n",
      "iteration:  50 cost:  [10721228.76538129]\n",
      "iteration:  51 cost:  [10685741.63937255]\n",
      "iteration:  52 cost:  [10652344.59395874]\n",
      "iteration:  53 cost:  [10620840.51143194]\n",
      "iteration:  54 cost:  [10591055.2773291]\n",
      "iteration:  55 cost:  [10562834.75224668]\n",
      "iteration:  56 cost:  [10536042.18055741]\n",
      "iteration:  57 cost:  [10510555.96848095]\n",
      "iteration:  58 cost:  [10486267.77490756]\n",
      "iteration:  59 cost:  [10463080.8674948]\n",
      "iteration:  60 cost:  [10440908.70415959]\n",
      "iteration:  61 cost:  [10419673.70643243]\n",
      "iteration:  62 cost:  [10399306.19643712]\n",
      "iteration:  63 cost:  [10379743.47368511]\n",
      "iteration:  64 cost:  [10360929.01157797]\n",
      "iteration:  65 cost:  [10342811.75661034]\n",
      "iteration:  66 cost:  [10325345.51586537]\n",
      "iteration:  67 cost:  [10308488.42057576]\n",
      "iteration:  68 cost:  [10292202.45535486]\n",
      "iteration:  69 cost:  [10276453.04424541]\n",
      "iteration:  70 cost:  [10261208.68602998]\n",
      "iteration:  71 cost:  [10246440.6323451]\n",
      "iteration:  72 cost:  [10232122.60306428]\n",
      "iteration:  73 cost:  [10218230.53420045]\n",
      "iteration:  74 cost:  [10204742.35424059]\n",
      "iteration:  75 cost:  [10191637.78539039]\n",
      "iteration:  76 cost:  [10178898.16668544]\n",
      "iteration:  77 cost:  [10166506.29633442]\n",
      "iteration:  78 cost:  [10154446.29100874]\n",
      "iteration:  79 cost:  [10142703.46009151]\n",
      "iteration:  80 cost:  [10131264.19315455]\n",
      "iteration:  81 cost:  [10120115.85915212]\n",
      "iteration:  82 cost:  [10109246.71600929]\n",
      "iteration:  83 cost:  [10098645.82944568]\n",
      "iteration:  84 cost:  [10088303.00001692]\n",
      "iteration:  85 cost:  [10078208.69747844]\n",
      "iteration:  86 cost:  [10068354.00168135]\n",
      "iteration:  87 cost:  [10058730.54930404]\n",
      "iteration:  88 cost:  [10049330.48580213]\n",
      "iteration:  89 cost:  [10040146.42203052]\n",
      "iteration:  90 cost:  [10031171.39505268]\n",
      "iteration:  91 cost:  [10022398.83270624]\n",
      "iteration:  92 cost:  [10013822.52154101]\n",
      "iteration:  93 cost:  [10005436.57778833]\n",
      "iteration:  94 cost:  [9997235.42105606]\n",
      "iteration:  95 cost:  [9989213.75047728]\n",
      "iteration:  96 cost:  [9981366.52306874]\n",
      "iteration:  97 cost:  [9973688.93408161]\n",
      "iteration:  98 cost:  [9966176.39914779]\n",
      "iteration:  99 cost:  [9958824.53804812]\n",
      "iteration:  100 cost:  [9951629.15994382]\n",
      "iteration:  101 cost:  [9944586.24993022]\n",
      "iteration:  102 cost:  [9937691.95678595]\n",
      "iteration:  103 cost:  [9930942.58180271]\n",
      "iteration:  104 cost:  [9924334.56859285]\n",
      "iteration:  105 cost:  [9917864.49378229]\n",
      "iteration:  106 cost:  [9911529.05850466]\n",
      "iteration:  107 cost:  [9905325.08062149]\n",
      "iteration:  108 cost:  [9899249.48760046]\n",
      "iteration:  109 cost:  [9893299.30999049]\n",
      "iteration:  110 cost:  [9887471.67543759]\n",
      "iteration:  111 cost:  [9881763.80319202]\n",
      "iteration:  112 cost:  [9876172.99906114]\n",
      "iteration:  113 cost:  [9870696.65076699]\n",
      "iteration:  114 cost:  [9865332.22367181]\n",
      "iteration:  115 cost:  [9860077.25683777]\n",
      "iteration:  116 cost:  [9854929.35939087]\n",
      "iteration:  117 cost:  [9849886.20716094]\n",
      "iteration:  118 cost:  [9844945.53957397]\n",
      "iteration:  119 cost:  [9840105.15677311]\n",
      "iteration:  120 cost:  [9835362.91694885]\n",
      "iteration:  121 cost:  [9830716.73385946]\n",
      "iteration:  122 cost:  [9826164.57452486]\n",
      "iteration:  123 cost:  [9821704.45707929]\n",
      "iteration:  124 cost:  [9817334.44876836]\n",
      "iteration:  125 cost:  [9813052.6640784]\n",
      "iteration:  126 cost:  [9808857.26298678]\n",
      "iteration:  127 cost:  [9804746.44932265]\n",
      "iteration:  128 cost:  [9800718.46922909]\n",
      "iteration:  129 cost:  [9796771.609718]\n",
      "iteration:  130 cost:  [9792904.19731005]\n",
      "iteration:  131 cost:  [9789114.59675287]\n",
      "iteration:  132 cost:  [9785401.20981099]\n",
      "iteration:  133 cost:  [9781762.47412167]\n",
      "iteration:  134 cost:  [9778196.86211159]\n",
      "iteration:  135 cost:  [9774702.87996947]\n",
      "iteration:  136 cost:  [9771279.06667045]\n",
      "iteration:  137 cost:  [9767923.99304792]\n",
      "iteration:  138 cost:  [9764636.26090968]\n",
      "iteration:  139 cost:  [9761414.50219479]\n",
      "iteration:  140 cost:  [9758257.37816826]\n",
      "iteration:  141 cost:  [9755163.57865092]\n",
      "iteration:  142 cost:  [9752131.82128168]\n",
      "iteration:  143 cost:  [9749160.85081053]\n",
      "iteration:  144 cost:  [9746249.43841936]\n",
      "iteration:  145 cost:  [9743396.38106955]\n",
      "iteration:  146 cost:  [9740600.50087404]\n",
      "iteration:  147 cost:  [9737860.64449243]\n",
      "iteration:  148 cost:  [9735175.68254788]\n",
      "iteration:  149 cost:  [9732544.50906427]\n",
      "iteration:  150 cost:  [9729966.04092212]\n",
      "iteration:  151 cost:  [9727439.21733321]\n",
      "iteration:  152 cost:  [9724962.99933117]\n",
      "iteration:  153 cost:  [9722536.36927915]\n",
      "iteration:  154 cost:  [9720158.3303916]\n",
      "iteration:  155 cost:  [9717827.90627122]\n",
      "iteration:  156 cost:  [9715544.140459]\n",
      "iteration:  157 cost:  [9713306.09599734]\n",
      "iteration:  158 cost:  [9711112.85500563]\n",
      "iteration:  159 cost:  [9708963.51826725]\n",
      "iteration:  160 cost:  [9706857.20482807]\n",
      "iteration:  161 cost:  [9704793.05160527]\n",
      "iteration:  162 cost:  [9702770.21300687]\n",
      "iteration:  163 cost:  [9700787.86056048]\n",
      "iteration:  164 cost:  [9698845.18255197]\n",
      "iteration:  165 cost:  [9696941.38367281]\n",
      "iteration:  166 cost:  [9695075.68467629]\n",
      "iteration:  167 cost:  [9693247.32204184]\n",
      "iteration:  168 cost:  [9691455.54764777]\n",
      "iteration:  169 cost:  [9689699.62845138]\n",
      "iteration:  170 cost:  [9687978.84617685]\n",
      "iteration:  171 cost:  [9686292.49701011]\n",
      "iteration:  172 cost:  [9684639.89130103]\n",
      "iteration:  173 cost:  [9683020.35327203]\n",
      "iteration:  174 cost:  [9681433.22073355]\n",
      "iteration:  175 cost:  [9679877.84480568]\n",
      "iteration:  176 cost:  [9678353.58964605]\n",
      "iteration:  177 cost:  [9676859.83218377]\n",
      "iteration:  178 cost:  [9675395.96185901]\n",
      "iteration:  179 cost:  [9673961.38036853]\n",
      "iteration:  180 cost:  [9672555.50141628]\n",
      "iteration:  181 cost:  [9671177.75046989]\n",
      "iteration:  182 cost:  [9669827.5645219]\n",
      "iteration:  183 cost:  [9668504.39185632]\n",
      "iteration:  184 cost:  [9667207.69182008]\n",
      "iteration:  185 cost:  [9665936.93459936]\n",
      "iteration:  186 cost:  [9664691.6010004]\n",
      "iteration:  187 cost:  [9663471.18223519]\n",
      "iteration:  188 cost:  [9662275.17971152]\n",
      "iteration:  189 cost:  [9661103.10482734]\n",
      "iteration:  190 cost:  [9659954.4787693]\n",
      "iteration:  191 cost:  [9658828.83231584]\n",
      "iteration:  192 cost:  [9657725.70564393]\n",
      "iteration:  193 cost:  [9656644.64813997]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  194 cost:  [9655585.21821453]\n",
      "iteration:  195 cost:  [9654546.98312108]\n",
      "iteration:  196 cost:  [9653529.51877804]\n",
      "iteration:  197 cost:  [9652532.40959478]\n",
      "iteration:  198 cost:  [9651555.24830126]\n",
      "iteration:  199 cost:  [9650597.63578064]\n",
      "iteration:  200 cost:  [9649659.18090593]\n",
      "iteration:  201 cost:  [9648739.50037943]\n",
      "iteration:  202 cost:  [9647838.21857579]\n",
      "iteration:  203 cost:  [9646954.96738803]\n",
      "iteration:  204 cost:  [9646089.38607685]\n",
      "iteration:  205 cost:  [9645241.12112273]\n",
      "iteration:  206 cost:  [9644409.82608147]\n",
      "iteration:  207 cost:  [9643595.16144206]\n",
      "iteration:  208 cost:  [9642796.79448793]\n",
      "iteration:  209 cost:  [9642014.39916078]\n",
      "iteration:  210 cost:  [9641247.65592712]\n",
      "iteration:  211 cost:  [9640496.25164753]\n",
      "iteration:  212 cost:  [9639759.87944862]\n",
      "iteration:  213 cost:  [9639038.23859758]\n",
      "iteration:  214 cost:  [9638331.03437915]\n",
      "iteration:  215 cost:  [9637637.97797503]\n",
      "iteration:  216 cost:  [9636958.7863459]\n",
      "iteration:  217 cost:  [9636293.1821157]\n",
      "iteration:  218 cost:  [9635640.89345814]\n",
      "iteration:  219 cost:  [9635001.65398579]\n",
      "iteration:  220 cost:  [9634375.202641]\n",
      "iteration:  221 cost:  [9633761.28358928]\n",
      "iteration:  222 cost:  [9633159.64611474]\n",
      "iteration:  223 cost:  [9632570.04451775]\n",
      "iteration:  224 cost:  [9631992.23801427]\n",
      "iteration:  225 cost:  [9631425.99063776]\n",
      "iteration:  226 cost:  [9630871.07114258]\n",
      "iteration:  227 cost:  [9630327.25290953]\n",
      "iteration:  228 cost:  [9629794.31385338]\n",
      "iteration:  229 cost:  [9629272.03633195]\n",
      "iteration:  230 cost:  [9628760.20705733]\n",
      "iteration:  231 cost:  [9628258.61700875]\n",
      "iteration:  232 cost:  [9627767.06134713]\n",
      "iteration:  233 cost:  [9627285.33933136]\n",
      "iteration:  234 cost:  [9626813.25423648]\n",
      "iteration:  235 cost:  [9626350.61327316]\n",
      "iteration:  236 cost:  [9625897.22750896]\n",
      "iteration:  237 cost:  [9625452.91179119]\n",
      "iteration:  238 cost:  [9625017.48467139]\n",
      "iteration:  239 cost:  [9624590.76833099]\n",
      "iteration:  240 cost:  [9624172.58850889]\n",
      "iteration:  241 cost:  [9623762.77443014]\n",
      "iteration:  242 cost:  [9623361.15873628]\n",
      "iteration:  243 cost:  [9622967.57741698]\n",
      "iteration:  244 cost:  [9622581.86974291]\n",
      "iteration:  245 cost:  [9622203.87820038]\n",
      "iteration:  246 cost:  [9621833.4484267]\n",
      "iteration:  247 cost:  [9621470.42914733]\n",
      "iteration:  248 cost:  [9621114.67211404]\n",
      "iteration:  249 cost:  [9620766.03204435]\n",
      "iteration:  250 cost:  [9620424.36656225]\n",
      "iteration:  251 cost:  [9620089.53613997]\n",
      "iteration:  252 cost:  [9619761.40404108]\n",
      "iteration:  253 cost:  [9619439.83626454]\n",
      "iteration:  254 cost:  [9619124.70149011]\n",
      "iteration:  255 cost:  [9618815.87102462]\n",
      "iteration:  256 cost:  [9618513.2187495]\n",
      "iteration:  257 cost:  [9618216.62106909]\n",
      "iteration:  258 cost:  [9617925.95686041]\n",
      "iteration:  259 cost:  [9617641.10742351]\n",
      "iteration:  260 cost:  [9617361.95643311]\n",
      "iteration:  261 cost:  [9617088.389891]\n",
      "iteration:  262 cost:  [9616820.29607955]\n",
      "iteration:  263 cost:  [9616557.56551605]\n",
      "iteration:  264 cost:  [9616300.09090806]\n",
      "iteration:  265 cost:  [9616047.76710947]\n",
      "iteration:  266 cost:  [9615800.4910777]\n",
      "iteration:  267 cost:  [9615558.16183154]\n",
      "iteration:  268 cost:  [9615320.6804099]\n",
      "iteration:  269 cost:  [9615087.94983146]\n",
      "iteration:  270 cost:  [9614859.87505499]\n",
      "iteration:  271 cost:  [9614636.36294064]\n",
      "iteration:  272 cost:  [9614417.32221179]\n",
      "iteration:  273 cost:  [9614202.66341778]\n",
      "iteration:  274 cost:  [9613992.29889752]\n",
      "iteration:  275 cost:  [9613786.14274353]\n",
      "iteration:  276 cost:  [9613584.11076696]\n",
      "iteration:  277 cost:  [9613386.12046313]\n",
      "iteration:  278 cost:  [9613192.0909779]\n",
      "iteration:  279 cost:  [9613001.9430746]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-46077d9b14d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0m_thetas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalized_input_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_thetas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"iteration: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"cost: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalized_input_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_thetas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-46077d9b14d9>\u001b[0m in \u001b[0;36mgradient_descent\u001b[1;34m(inputs, outputs, thetas, alpha)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthetas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# use inputs[:,j] to get the corresponding feature column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mpartial_derivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mnew_thetas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthetas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_thetas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-46077d9b14d9>\u001b[0m in \u001b[0;36mpartial_derivative\u001b[1;34m(inputs, outputs, thetas, x_terms)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# sum of the difference * the matching feature x_term / m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0msum_d\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhypothesis_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx_terms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msum_d\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# hypothesis funciton\n",
    "def hypothesis_function(input_data, thetas):\n",
    "    # transpose theta so it is now vertical and ready for multiplcation\n",
    "    thetasT = thetas.reshape(1, thetas.shape[0])\n",
    "    # multiply to find the prediction value\n",
    "    return np.matmul(thetasT, input_data)\n",
    "\n",
    "# cost function\n",
    "def cost_function(inputs, outputs, thetas):\n",
    "    sum_cost = 0\n",
    "    m = inputs.shape[0]\n",
    "    # sum of the difference squared / 2m\n",
    "    for i in range(m):\n",
    "        sum_cost += np.square(hypothesis_function(inputs[i], thetas) - outputs[i])\n",
    "    return sum_cost / (2 * m)\n",
    "\n",
    "def partial_derivative(inputs, outputs, thetas, x_terms):\n",
    "    sum_d = 0\n",
    "    m = inputs.shape[0]\n",
    "    # sum of the difference * the matching feature x_term / m\n",
    "    for i in range(m):\n",
    "        sum_d += (hypothesis_function(inputs[i], thetas) - outputs[i]) * x_terms[i]\n",
    "    return sum_d / m\n",
    "\n",
    "def gradient_descent(inputs, outputs, thetas, alpha):\n",
    "    new_thetas = np.zeros(thetas.shape[0])\n",
    "    # for each theta calculate the partial derivative\n",
    "    for j in range(thetas.shape[0]):\n",
    "        # use inputs[:,j] to get the corresponding feature column\n",
    "        step = alpha * partial_derivative(inputs, outputs, thetas, inputs[:,j])\n",
    "        new_thetas[j] = thetas[j] - step\n",
    "    return new_thetas\n",
    "\n",
    "# learning rate\n",
    "a = 1.5\n",
    "iterations = 1000\n",
    "\n",
    "# parameters\n",
    "_thetas = np.zeros(input_data.shape[1])\n",
    "\n",
    "normalized_input_data = np.zeros((input_data.shape[0], input_data.shape[1]))\n",
    "for i in range(0, input_data.shape[1]):\n",
    "    if (i == 0):\n",
    "        for j in range(input_data.shape[0]):\n",
    "            normalized_input_data[j,i] = 1\n",
    "    else:\n",
    "        a_max = np.max(input_data[:,i])\n",
    "        a_min = np.min(input_data[:,i])\n",
    "        for j in range(input_data.shape[0]):\n",
    "            normalized_input_data[j, i] = input_data[j, i] / (a_max - a_min)\n",
    "print(normalized_input_data)\n",
    "print('cost before:', cost_function(normalized_input_data, output_data, _thetas))\n",
    "\n",
    "for i in range(iterations):\n",
    "    _thetas = gradient_descent(normalized_input_data, output_data, _thetas, a)\n",
    "    print(\"iteration: \", i, \"cost: \", cost_function(normalized_input_data, output_data, _thetas))\n",
    "    \n",
    "print('cost after:',cost_function(normalized_input_data, output_data, _thetas))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "\n",
    "ax.scatter3D(normalized_input_data[:,1], normalized_input_data[:,2], output_data)\n",
    "\n",
    "x_lin = np.linspace(0, np.max(normalized_input_data[:,1]), normalized_input_data.shape[0])\n",
    "y_lin = np.linspace(0, np.max(normalized_input_data[:,2]), normalized_input_data.shape[0])\n",
    "z_lin = np.zeros(normalized_input_data.shape[0])\n",
    "\n",
    "for i in range(normalized_input_data.shape[0]):\n",
    "    z_lin[i] = hypothesis_function([1, x_lin[i], y_lin[i]], _thetas)\n",
    "    \n",
    "def fun(x, y):\n",
    "    return x**2 + y\n",
    "    \n",
    "X, Y = np.meshgrid(x_lin, y_lin)\n",
    "zs = np.array(fun(np.ravel(X), np.ravel(Y)))\n",
    "Z = zs.reshape(X.shape)\n",
    "ax.plot_surface(X, Y, Z)\n",
    "\n",
    "print(hypothesis_function([1, 10000, 2], _thetas))\n",
    "\n",
    "ax.set_xlabel(\"Milage (miles)\")\n",
    "ax.set_ylabel(\"Engine Size\")\n",
    "ax.set_zlabel(\"Price ($)\")\n",
    "\n",
    "print(_thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-cliff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
