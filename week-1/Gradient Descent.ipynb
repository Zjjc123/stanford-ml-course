{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beginning-throw",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "\n",
    "Solve for minimum of the cost function\n",
    "\n",
    "- Start with some $\\theta_0, \\theta_1$\n",
    "- Keep changing  $\\theta_0, \\theta_1$ to reduce $J(\\theta_0, \\theta_1)$ until we hopefully end up at the minimum.\n",
    "\n",
    "## Algorithm\n",
    "\n",
    "**:= ⇒ assignment**\n",
    "\n",
    "$**\\alpha$ ⇒ learning rate - how big are the gradient descent steps**\n",
    "\n",
    "$**\\partial$ ⇒ partial derivative** - taking derivative with respect to one variable while holding the other one constant\n",
    "\n",
    "repeat until convergence {\n",
    "\t$\\theta_j:=\\theta_j-\\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta_0,\\theta_1)$ (for j = 0 and j = 1)\n",
    "}\n",
    "\n",
    "**Simultaneously update all the $\\theta$ parameters!!**\n",
    "\n",
    "### Correct Implementation\n",
    "\n",
    "temp0 $:=\\theta_0-\\alpha\\frac{\\partial}{\\partial\\theta_0}J(\\theta_0,\\theta_1)$\n",
    "\n",
    "temp1 $:=\\theta_1-\\alpha\\frac{\\partial}{\\partial\\theta_1}J(\\theta_0,\\theta_1)$\n",
    "\n",
    "$\\theta_0:=$ temp0\n",
    "\n",
    "$\\theta_1:=$ temp1\n",
    "\n",
    "***incorrect to update one parameter before calculating the other**\n",
    "\n",
    "- if $\\alpha$ is too small, gradient descent can be slow\n",
    "- if $\\alpha$ is too large, gradient descent can overshoot the minimum, it may fail to converge, or even diverge.\n",
    "\n",
    "**Batch** **Gradient Descent** **-** each step of gradient descent uses all the training examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-sunglasses",
   "metadata": {},
   "source": [
    "## Gradient Descent for Linear Regression\n",
    "\n",
    "$\\frac{\\partial}{\\partial\\theta_j}J(\\theta_0, \\theta_1) = \\frac{\\partial}{\\partial\\theta_j}\\frac{1}{2m}\\sum^m_{i = 1}(h_\\theta(x^{(i)}) - y^{(i)})^2$\n",
    "\n",
    "$\\frac{\\partial}{\\partial\\theta_j}J(\\theta_0, \\theta_1) = \\frac{\\partial}{\\partial\\theta_j}\\frac{1}{2m}\\sum^m_{i = 1}(\\theta_0 + \\theta_1 x^{(i)} - y^{(i)})^2$\n",
    "\n",
    "### Simple Multivariable Calculus\n",
    "\n",
    "$j=0:\\frac{\\partial}{\\partial\\theta_0}J(\\theta_0, \\theta_1) = \\frac{2}{2m}\\sum^m_{i = 1}(\\theta_0 + \\theta_1 x^{(i)} - y^{(i)}) (1) = \\frac{1}{m}\\sum^m_{i = 1}(h_\\theta(x^{(j)} - y^{(i)})$ \n",
    "\n",
    "$j=1:\\frac{\\partial}{\\partial\\theta_1}J(\\theta_0, \\theta_1) = \\frac{2}{2m}\\sum^m_{i = 1}(\\theta_0 + \\theta_1 x^{(i)} - y^{(i)}) (x^{(i)}) = \\frac{1}{m}\\sum^m_{i = 1}(h_\\theta(x^{(j)} - y^{(i)})(x^{(i)})$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
